{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2      3      4      5      6     7\n",
       "0  15.26  14.84  0.8710  5.763  3.312  2.221  5.220  Kama\n",
       "1  14.88  14.57  0.8811  5.554  3.333  1.018  4.956  Kama\n",
       "2  14.29  14.09  0.9050  5.291  3.337  2.699  4.825  Kama\n",
       "3  13.84  13.94  0.8955  5.324  3.379  2.259  4.805  Kama\n",
       "4  16.14  14.99  0.9034  5.658  3.562  1.355  5.175  Kama"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import isotonic\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "path = r\"./seeds.tsv\"\n",
    "data = pd.read_csv(path, header=None, sep = '\\t')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1]\n",
    "y = data[7]\n",
    "mydict = {'Kama':1, 'Rosa':2, 'Canadian':3}\n",
    "# 得到训练和测试数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=0.85)\n",
    "y_train = y_train.map(mydict) #把非字符型数据映射为字符型数据\n",
    "y_test = y_test.map(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "knc.fit(x_train, y_train)\n",
    "score = knc.score(x_test, y_test)\n",
    "print(score)\n",
    "# 准确率很高，此时只要输入小麦数据就可以对小麦种类进行预测了\n",
    "knc.predict([x_test.iloc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性回归算法，最小二乘法，函数名 LinearRegression\n",
    "def mx_line(train_x, train_y):\n",
    "    mx = LinearRegression()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 逻辑回归算法，函数名, LogisticRegression\n",
    "def mx_log(train_x, train_y):\n",
    "#     mx = LogisticRegression(penalty='12')\n",
    "    mx = LogisticRegression()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 多项式朴素贝叶斯算法，Multinomial Naive Bayes，函数名，multinomialnb\n",
    "def mx_bayes(train_x, train_y):\n",
    "    mx = MultinomialNB(alpha=0.01)\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "mx = mx_bayes(x_train, y_train)\n",
    "mx.score(x_test, y_test)\n",
    "\n",
    "# KNN近邻算法，函数名，KNeighborsClassifier\n",
    "def mx_knn(train_x, train_y):\n",
    "    mx = KNeighborsClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 随机随机森林算法,random forest classifier，函数名,RandomForestClassifier\n",
    "def mx_forest(train_x, train_y):\n",
    "    mx = RandomForestClassifier(n_estimators=8)\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 决策树方法\n",
    "def mx_dtree(train_x, train_y):\n",
    "    mx = tree.DecisionTreeClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# GBDT迭代决策树算法，Gradient Boosting Decision Tree,\n",
    "# 又叫MART(Multiple Additive Regression Tree)，函数名，GradientBoostingClassifier\n",
    "def mx_GBDT(train_x, train_y):\n",
    "    mx = GradientBoostingClassifier(n_estimators=200)\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# SVM向量机算法，函数名 SVC\n",
    "def mx_svm(train_x, train_y):\n",
    "    mx = SVC(kernel='rbf', probability=True)\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# SVM-cross向量机交叉算法，函数名 SVC，自动调优\n",
    "def mx_svm_cross(train_x, train_y):\n",
    "    mx = SVC(kernel='rbf', probability=True)\n",
    "    param_grid = {'C':[1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma':[0.001, 0.0001]}\n",
    "    grid_search = GridSearchCV(mx, param_grid, n_jobs=1, verbose=1)\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    mx = SVC(kernel='rbf', C=best_parameters['C'], gamma=best_parameters['gamma'], probability=True)\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# MLP神经网络算法\n",
    "def mx_MLP(train_x, train_y):\n",
    "    # mx = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1)\n",
    "    mx = MLPClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 神经网络回归算法\n",
    "def mx_MLP_reg(train_x, train_y):\n",
    "    # mx = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1)\n",
    "    mx = MLPRegressor()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 岭回归算法\n",
    "def mx_Ridge(train_x, train_y):\n",
    "    mx = linear_model.Ridge()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# lasso回归(拉格朗日回归)\n",
    "def mx_Lasso(train_x, train_y):\n",
    "    mx = linear_model.Lasso()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 贝叶斯回归\n",
    "def mx_bayeslinear(train_x, train_y):\n",
    "    mx = linear_model.BayesianRidge()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 随机梯度\n",
    "def mx_SGDRegressor(train_x, train_y):\n",
    "    mx = linear_model.SGDRegressor()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 被动攻击算法\n",
    "def mx_PassiveAggressiveReg(train_x, train_y):\n",
    "    mx = linear_model.PassiveAggressiveRegressor()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 感知器算法\n",
    "def mx_Perceptron(train_x, train_y):\n",
    "    mx = linear_model.Perceptron()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 最小角回归\n",
    "def mx_Lars(train_x, train_y):\n",
    "    mx = linear_model.Lars()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# # 多任务弹性网络\n",
    "# def mx_MultiTaskElastic(train_x, train_y):\n",
    "#     mx = linear_model.MultiTaskElasticNet()\n",
    "#     mx.fit(train_x, train_y)\n",
    "#     return mx\n",
    "\n",
    "# 弹性网络\n",
    "def mx_ElasticNetCV(train_x, train_y):\n",
    "    mx = linear_model.ElasticNetCV()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# # 多任务lasso回归\n",
    "# def mx_MultiTaskLasso(train_x, train_y):\n",
    "#     mx = linear_model.MultiTaskLasso()\n",
    "#     mx.fit(train_x, train_y)\n",
    "#     return mx\n",
    "\n",
    "# 多任务拉格朗日回归\n",
    "def mx_LassoLars(train_x, train_y):\n",
    "    mx = linear_model.LassoLars()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 主动决策\n",
    "def mx_ARDRegression(train_x, train_y):\n",
    "    mx = linear_model.ARDRegression()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 随机抽样一致性算法\n",
    "def mx_RANSACRegressor(train_x, train_y):\n",
    "    mx = linear_model.RANSACRegressor()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 广义中值估计\n",
    "def mx_TheilSenRegressor(train_x, train_y):\n",
    "    mx = linear_model.TheilSenRegressor()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# # huber回归\n",
    "# def mx_Huber(train_x, train_y):\n",
    "#     mx = linear_model.Huber()\n",
    "#     mx.fit(train_x, train_y)\n",
    "#     return mx\n",
    "\n",
    "# 随机梯度下降\n",
    "def mx_SGDClassifier(train_x, train_y):\n",
    "    mx = SGDClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 高斯过程分类器\n",
    "def mx_GaussianProcessRegressor(train_x, train_y):\n",
    "    mx = GaussianProcessRegressor()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 交叉分解\n",
    "def mx_PLSRegression(train_x, train_y):\n",
    "    mx = sklearn.cross_decomposition.PLSRegression()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "def mx_PLSCanonical(train_x, train_y):\n",
    "    mx = cross_decomposition.PLSCanonical()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 伯努利贝叶斯\n",
    "def mx_BernoulliNB(train_x, train_y):\n",
    "    mx = sklearn.naive_bayes.BernoulliNB()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 高斯贝叶斯\n",
    "def mx_GaussianNB(train_x, train_y):\n",
    "    mx = sklearn.naive_bayes.GaussianNB()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 元估计器\n",
    "def mx_BaggingClassifier(train_x, train_y):\n",
    "    mx = BaggingClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 极限组合森林\n",
    "def mx_EXtraTreeClassifier(train_x, train_y):\n",
    "    mx = ExtraTreesClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# AdaBoost(提升)算法\n",
    "def mx_AdaBoostClassifier(train_x, train_y):\n",
    "    mx = AdaBoostClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# 梯度树算法GradientBoostingClassifier\n",
    "def mx_GradientBoostingClassifier(train_x, train_y):\n",
    "    mx = GradientBoostingClassifier()\n",
    "    mx.fit(train_x, train_y)\n",
    "    return mx\n",
    "\n",
    "# # 投票分类器\n",
    "# def mx_VotingClassifier(train_x, train_y):\n",
    "#     mx = VotingClassifier()\n",
    "#     mx.fit(train_x, train_y)\n",
    "#     return mx\n",
    "\n",
    "# # 等式回归IsotonicRegression\n",
    "# def mx_IsotonicRegression(train_x, train_y):\n",
    "#     mx = isotonic.IsotonicRegression()\n",
    "#     mx.fit(train_x, train_y)\n",
    "#     return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxfunSgn = {'line': mx_line,\n",
    "            'log': mx_log,\n",
    "            'bayes': mx_bayes,\n",
    "            'knn': mx_knn,\n",
    "            'forest': mx_forest,\n",
    "            'dtree': mx_dtree,\n",
    "            'gbdt': mx_GBDT,\n",
    "            'svm': mx_svm,\n",
    "            'svmcr': mx_svm_cross,\n",
    "            'mlp': mx_MLP,\n",
    "            'mlppreg': mx_MLP_reg,\n",
    "            'Ridge': mx_Ridge,\n",
    "            'Lasso': mx_Lasso,\n",
    "            'bayeslinear': mx_bayeslinear,\n",
    "            'SGDRegressor': mx_SGDRegressor,\n",
    "            'PassiveAggressiveReg': mx_PassiveAggressiveReg,\n",
    "            'Perceptron': mx_Perceptron,\n",
    "            'Lars': mx_Lars,\n",
    "            'ElasticNetCV': mx_ElasticNetCV,\n",
    "            'LassoLars': mx_LassoLars,\n",
    "            'ARDRegression': mx_ARDRegression,\n",
    "            'RANSACRegressor': mx_RANSACRegressor,\n",
    "            'TheilSenRegressor': mx_TheilSenRegressor,\n",
    "            'SGDClassifier': mx_SGDClassifier,\n",
    "            'GaussianProcessRegressor': mx_GaussianProcessRegressor,\n",
    "            'PLSRegression': mx_PLSRegression,\n",
    "            'PLSCanonical': mx_PLSCanonical,\n",
    "            'BernoulliNB': mx_BernoulliNB,\n",
    "            'GaussianNB': mx_GaussianNB,\n",
    "            'BaggingClassifier': mx_BaggingClassifier,\n",
    "            'EXtraTreeClassifier': mx_EXtraTreeClassifier,\n",
    "            'AdaBoostClassifier': mx_AdaBoostClassifier,\n",
    "            'GradientBoostingClassifier': mx_GradientBoostingClassifier,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 0.7557101661141133\n",
      "log 0.875\n",
      "bayes 0.78125\n",
      "knn 0.84375\n",
      "forest 0.90625\n",
      "dtree 0.875\n",
      "gbdt 0.875\n",
      "svm 0.84375\n",
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:    0.3s finished\n",
      "e:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "e:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "e:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "e:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmcr 0.875\n",
      "mlp 0.21875\n",
      "mlppreg -0.43302227485154937\n",
      "Ridge 0.6717849511978878\n",
      "Lasso -0.0017420146601001552\n",
      "bayeslinear 0.7453384562126623\n",
      "SGDRegressor -211321163.797401\n",
      "PassiveAggressiveReg 0.409750380514384\n",
      "Perceptron 0.5625\n",
      "Lars 0.7709992391213228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetCV 0.7079153940423798\n",
      "LassoLars -0.0017420146601001552\n",
      "ARDRegression 0.7560085633658836\n",
      "RANSACRegressor 0.7610156450681377\n",
      "TheilSenRegressor 0.7622072535595171\n",
      "SGDClassifier 0.59375\n",
      "GaussianProcessRegressor 0.5037854211579966\n",
      "PLSRegression 0.47443252444180795\n",
      "PLSCanonical -0.6175730675310978\n",
      "BernoulliNB 0.21875\n",
      "GaussianNB 0.84375\n",
      "BaggingClassifier 0.90625\n",
      "EXtraTreeClassifier 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "e:\\anaconda3\\lib\\site-packages\\sklearn\\cross_decomposition\\pls_.py:287: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier 0.6875\n",
      "GradientBoostingClassifier 0.875\n"
     ]
    }
   ],
   "source": [
    "resultlist = {}\n",
    "for k in mxfunSgn:\n",
    "    mx = mxfunSgn[k](x_train, y_train)\n",
    "    score = mx.score(x_test, y_test)\n",
    "    print(k, score)\n",
    "    resultlist[k] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....max  : ['EXtraTreeClassifier'] 0.9375\n",
      "....nextmax  : ['BaggingClassifier', 'EXtraTreeClassifier']\n",
      "....nextmax  : BaggingClassifier 0.90625\n",
      "....thirdmax  : forest 0.90625\n"
     ]
    }
   ],
   "source": [
    "print(\"....max  :\", sorted(resultlist, key=lambda x:resultlist[x])[-1:],\n",
    "      resultlist[sorted(resultlist, key=lambda x:resultlist[x])[-1]])\n",
    "print(\"....nextmax  :\", sorted(resultlist, key=lambda x:resultlist[x])[-2:])\n",
    "print(\"....nextmax  :\", sorted(resultlist, key=lambda x:resultlist[x])[-2],\n",
    "      resultlist[sorted(resultlist, key=lambda x:resultlist[x])[-2]])\n",
    "print(\"....thirdmax  :\", sorted(resultlist, key=lambda x:resultlist[x])[-3],\n",
    "      resultlist[sorted(resultlist, key=lambda x:resultlist[x])[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
